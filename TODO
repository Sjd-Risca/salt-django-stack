TODO

- find a way to pass the environment to use for starting Django, which will determine the value of DJANGO_SETTINGS_MODULE used when --settings not passed to django-admin.py and used automatically when calling gunicorn, for now,using $PROJECTNAME.settings.local
- postgresql user and db are already being created, need to update django settings correctly, use basic settings for now, later I'll move to scoops-style settings
- using sqlite db from django5, set it up to create a db in postgresql and use it from django
- at this point, all settings in django should be set by salt
- detect Ubuntu 14.10 to setup vcl for Varnish 4.0, test it manually first: https://www.varnish-cache.org/docs/4.0/whats-new/upgrading.html

- try again with Digital Ocean and 1 Gb. RAM for Varnish
- try keepalived with digital ocean tutorial, Python script is saved locally

- remove unused data from pillar zinibu_haproxy and zinibu_postgresql and any others

- States for deployment, probably named zinibu.deploy, and find best way to indicate if it's development, staging, production (pass via pillar in command line, see README and python states). I think I just need to consider one box as one environment so minions' ids are enough to target the states. This means no more having dev, staging and production all on the same box. Run from command line after merged to a branch I designate as the one feeding the environment, like "production" and "staging," and probably use git hooks so after something is merged to any of those branches the autodeployment runs

- move postgres-related lines from zinibu.python.init to postgres specific states, add include to zinibu.python.init.

- don't worry about high availability for redis and postgresql yet
- keepalived won't be used at the beginning for ha haproxy
- most destructive operations (umount, removing directories, uninstalls, etc) should be handled manually to avoid errors
- install redis and change settings to use it
- modifying settings.py in django to connect to db and dbsync/migrate as needed, see django formula for ideas

- logrotate to keep all logs under control (syslog-ng for something else?)

- I want to run the whole thing with:
sudo salt '*' state.highstate


- upgrade to varnish 4?

- I may continue without the keepalived shit. If I shutdown the keepalived service, it works. The problem is that backup is not becoming master as it shoud. The check script is working and priority is changing but still master remains master.

- Check about multicast, unicast, firewall and communicating between hosts with keepalived

http://serverfault.com/questions/512153/both-servers-running-keepalived-become-master-and-have-a-same-virtual-ip
http://www.cyberciti.biz/faq/linux-unix-verify-keepalived-working-or-not/

ping vrrp.mcast.net
iptables -L
sudo iptables -L
sudo tcpdump -vvv -n -i eth0 host 224.0.0.18
sudo iptables -I INPUT -i eth0 -d 224.0.0.0/8 -j ACCEPT
sudo iptables -L
sudo iptables -A INPUT -p 112 -i eth0 -j ACCEPT
sudo iptables -L
sudo iptables -A OUTPUT -p 112 -o eth0 -j ACCEPT
sudo iptables -L
sudo tcpdump -vvv -n -i eth0 host 224.0.0.18
sudo tcpdump -v -i eth0 host 224.0.0.18
sudo service keepalived restart
sudo service haproxy status


- check connections
netstat -ctnup | grep "192.168.1.95"

===
Linode tests

10/26/15 After Linode test 2:
- fix settings to use correct user, db info and more from pillar, see zinibu_dev/settings.py:STATIC_ROOT = '/home/vagrant/zinibu_dev/static'

10/25/15 After Linode test 1 ($ 0.33):
- focus on 14.04 LTS, 15.04 has replaced upstart with systemd and I don't want to mess with that for now, eventually I'll update these salt formulas to make a Django project run with systemd
====

